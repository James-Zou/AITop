# 机器学习基础概念

## 1. 机器学习概述

### 定义
机器学习是人工智能的一个子领域，它使计算机能够在没有明确编程的情况下学习和改进。

### 核心思想
- 从数据中学习模式
- 对新数据进行预测或决策
- 通过经验自动改进性能

## 2. 机器学习类型

### 2.1 监督学习 (Supervised Learning)
**定义**: 使用标记数据训练模型，学习输入到输出的映射关系。

**特点**:
- 有明确的输入-输出对
- 目标是最小化预测误差
- 可以评估模型性能

**常见算法**:
- 线性回归
- 逻辑回归
- 决策树
- 随机森林
- 支持向量机
- 神经网络

**应用场景**:
- 房价预测
- 邮件分类
- 图像识别
- 医疗诊断

### 2.2 无监督学习 (Unsupervised Learning)
**定义**: 从无标记数据中发现隐藏的模式和结构。

**特点**:
- 没有明确的输出标签
- 目标是发现数据的内在结构
- 评估相对困难

**常见算法**:
- K-means聚类
- 层次聚类
- 主成分分析(PCA)
- 自编码器
- 高斯混合模型

**应用场景**:
- 客户细分
- 异常检测
- 数据压缩
- 推荐系统

### 2.3 强化学习 (Reinforcement Learning)
**定义**: 智能体通过与环境交互，通过试错学习最优策略。

**核心要素**:
- 智能体 (Agent)
- 环境 (Environment)
- 状态 (State)
- 动作 (Action)
- 奖励 (Reward)
- 策略 (Policy)

**常见算法**:
- Q-Learning
- SARSA
- 策略梯度
- Actor-Critic
- DQN

**应用场景**:
- 游戏AI
- 机器人控制
- 自动驾驶
- 交易策略

## 3. 核心概念

### 3.1 过拟合与欠拟合

**过拟合 (Overfitting)**:
- 模型在训练数据上表现很好，但在测试数据上表现差
- 模型过于复杂，记住了训练数据的噪声
- 解决方法：正则化、交叉验证、早停、数据增强

**欠拟合 (Underfitting)**:
- 模型过于简单，无法捕捉数据中的模式
- 在训练和测试数据上都表现差
- 解决方法：增加模型复杂度、特征工程、减少正则化

### 3.2 偏差-方差权衡

**偏差 (Bias)**:
- 模型预测值与真实值之间的系统性误差
- 高偏差通常导致欠拟合

**方差 (Variance)**:
- 模型对训练数据变化的敏感性
- 高方差通常导致过拟合

**权衡关系**:
- 降低偏差会增加方差
- 降低方差会增加偏差
- 目标是找到最优平衡点

### 3.3 交叉验证

**目的**: 评估模型的泛化能力

**K折交叉验证**:
1. 将数据分为K个相等的子集
2. 用K-1个子集训练，1个子集验证
3. 重复K次，每次使用不同的验证集
4. 计算K次验证结果的平均值

**优点**:
- 充分利用数据
- 减少随机性影响
- 提供性能估计的置信区间

## 4. 评估指标

### 4.1 分类问题

**准确率 (Accuracy)**:
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

**精确率 (Precision)**:
```
Precision = TP / (TP + FP)
```

**召回率 (Recall)**:
```
Recall = TP / (TP + FN)
```

**F1分数**:
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

**AUC-ROC**:
- 接收者操作特征曲线下的面积
- 衡量分类器区分正负样本的能力

### 4.2 回归问题

**均方误差 (MSE)**:
```
MSE = (1/n) * Σ(y_true - y_pred)²
```

**均方根误差 (RMSE)**:
```
RMSE = √MSE
```

**平均绝对误差 (MAE)**:
```
MAE = (1/n) * Σ|y_true - y_pred|
```

**R²分数**:
```
R² = 1 - (SS_res / SS_tot)
```

## 5. 特征工程

### 5.1 特征选择
- 过滤法：基于统计特征选择
- 包装法：基于模型性能选择
- 嵌入法：在模型训练过程中选择

### 5.2 特征变换
- 标准化：均值0，方差1
- 归一化：缩放到[0,1]范围
- 对数变换：处理偏态分布
- 多项式特征：增加特征交互

### 5.3 特征构造
- 领域知识指导
- 自动特征生成
- 特征组合

## 6. 模型选择

### 6.1 选择标准
- 数据规模
- 特征数量
- 数据质量
- 计算资源
- 可解释性要求

### 6.2 集成方法
- Bagging：并行训练多个模型
- Boosting：串行训练，关注错误样本
- Stacking：用元模型组合多个模型

## 7. 实践建议

### 7.1 数据准备
1. 数据清洗和预处理
2. 探索性数据分析(EDA)
3. 特征工程
4. 数据分割

### 7.2 模型训练
1. 选择合适的算法
2. 超参数调优
3. 交叉验证
4. 模型评估

### 7.3 模型部署
1. 性能监控
2. 模型更新
3. 版本管理
4. 回滚机制

## 8. 常见陷阱

1. **数据泄露**: 测试数据信息泄露到训练过程
2. **选择偏差**: 数据收集过程中的系统性偏差
3. **过拟合**: 模型过度适应训练数据
4. **评估不当**: 使用不合适的评估指标
5. **特征工程不足**: 没有充分利用领域知识

## 9. 学习资源

### 经典教材

### 在线课程

### 实践平台
