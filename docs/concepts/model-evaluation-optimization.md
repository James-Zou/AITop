# 模型评估与优化

## 1. 模型评估基础

### 评估目标
- 性能评估：衡量模型在特定任务上的表现
- 泛化能力：评估模型在新数据上的表现
- 稳定性：评估模型性能的稳定性
- 鲁棒性：评估模型对噪声和异常值的抵抗能力

### 评估原则
- 客观性：使用客观的指标进行评估
- 全面性：从多个维度进行评估
- 可比性：使用标准化的评估方法
- 可重复性：评估结果可以重复验证

## 2. 分类任务评估

### 混淆矩阵
混淆矩阵是分类任务评估的基础工具。

**二分类混淆矩阵**:
```
                预测
实际    正类    负类
正类    TP      FN
负类    FP      TN
```

**多分类混淆矩阵**:
- 行表示真实类别
- 列表示预测类别
- 对角线元素表示正确分类

### 基本指标

**准确率(Accuracy)**:
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
- 定义：正确预测的样本数占总样本数的比例
- 优点：直观易懂
- 缺点：在类别不平衡时可能误导

**精确率(Precision)**:
```
Precision = TP / (TP + FP)
```
- 定义：预测为正类的样本中真正为正类的比例
- 意义：衡量预测的准确性
- 应用：当假正例成本高时重要

**召回率(Recall)**:
```
Recall = TP / (TP + FN)
```
- 定义：真正为正类的样本中被正确预测的比例
- 意义：衡量预测的完整性
- 应用：当假负例成本高时重要

**F1分数**:
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```
- 定义：精确率和召回率的调和平均
- 优点：平衡精确率和召回率
- 应用：当需要平衡两个指标时

### 高级指标

**Fβ分数**:
```
Fβ = (1 + β²) × (Precision × Recall) / (β² × Precision + Recall)
```
- β > 1：更重视召回率
- β < 1：更重视精确率
- β = 1：等同于F1分数

**AUC-ROC**:
- 定义：ROC曲线下的面积
- 范围：0-1，越高越好
- 优点：阈值无关，类别不平衡不敏感
- 缺点：只适用于二分类

**AUC-PR**:
- 定义：精确率-召回率曲线下的面积
- 适用：类别不平衡的二分类
- 优点：更关注正类性能

**马修斯相关系数(MCC)**:
```
MCC = (TP × TN - FP × FN) / √((TP + FP)(TP + FN)(TN + FP)(TN + FN))
```
- 范围：-1到1
- 优点：平衡所有类别
- 缺点：计算复杂

## 3. 回归任务评估

### 基本指标

**均方误差(MSE)**:
```
MSE = (1/n) × Σ(y_true - y_pred)²
```
- 定义：预测值与真实值差的平方的平均值
- 单位：与目标变量相同
- 特点：对大误差惩罚更重

**均方根误差(RMSE)**:
```
RMSE = √MSE
```
- 定义：MSE的平方根
- 单位：与目标变量相同
- 优点：与目标变量同量级

**平均绝对误差(MAE)**:
```
MAE = (1/n) × Σ|y_true - y_pred|
```
- 定义：预测值与真实值差的绝对值的平均值
- 单位：与目标变量相同
- 特点：对大误差不敏感

**平均绝对百分比误差(MAPE)**:
```
MAPE = (100/n) × Σ|y_true - y_pred| / |y_true|
```
- 定义：相对误差的百分比
- 范围：0到无穷大
- 优点：无量纲，易于理解
- 缺点：当真实值接近0时不稳定

### 高级指标

**R²分数**:
```
R² = 1 - (SS_res / SS_tot)
```
- 定义：决定系数
- 范围：-∞到1
- 1：完美预测
- 0：与均值预测相同
- 负值：比均值预测还差

**调整R²**:
```
R²_adj = 1 - (1 - R²) × (n - 1) / (n - p - 1)
```
- 定义：考虑特征数量的R²
- 优点：避免过拟合
- 应用：特征选择

**平均绝对误差百分比(MAPE)**:
```
MAPE = (100/n) × Σ|y_true - y_pred| / |y_true|
```
- 定义：相对误差的百分比
- 范围：0到无穷大
- 优点：易于理解
- 缺点：不对称，偏向负误差

## 4. 交叉验证

### 定义
交叉验证是将数据集分成多个子集，轮流使用其中一个子集作为验证集，其余作为训练集。

### 类型

**K折交叉验证**:
1. 将数据随机分为K个相等的子集
2. 用K-1个子集训练，1个子集验证
3. 重复K次，每次使用不同的验证集
4. 计算K次验证结果的平均值

**留一交叉验证(LOOCV)**:
- K = n（样本数）
- 每次留一个样本作为验证集
- 优点：充分利用数据
- 缺点：计算复杂度高

**分层K折交叉验证**:
- 保持每个折中类别比例相同
- 适用于类别不平衡的数据
- 优点：更稳定的评估结果

**时间序列交叉验证**:
- 按时间顺序分割数据
- 避免数据泄露
- 适用于时间序列数据

### 选择策略
- **小数据集**：使用LOOCV
- **大数据集**：使用5-10折交叉验证
- **类别不平衡**：使用分层交叉验证
- **时间序列**：使用时间序列交叉验证

## 5. 模型选择

### 选择标准
- **性能指标**：准确率、F1分数、AUC等
- **计算复杂度**：训练时间、推理时间
- **内存使用**：模型大小、内存占用
- **可解释性**：模型的可解释程度
- **稳定性**：性能的稳定性

### 选择方法

**网格搜索**:
- 遍历所有参数组合
- 优点：全面搜索
- 缺点：计算复杂度高

**随机搜索**:
- 随机采样参数组合
- 优点：计算效率高
- 缺点：可能错过最优解

**贝叶斯优化**:
- 使用贝叶斯方法指导搜索
- 优点：智能搜索，效率高
- 缺点：实现复杂

**进化算法**:
- 使用遗传算法等进化算法
- 优点：全局搜索能力强
- 缺点：收敛速度慢

## 6. 超参数调优

### 定义
超参数调优是选择最优超参数的过程。

### 超参数类型
- **学习率**：控制参数更新步长
- **批次大小**：每次训练的样本数
- **正则化参数**：控制过拟合
- **网络结构**：层数、神经元数
- **激活函数**：ReLU、Sigmoid等

### 调优方法

**网格搜索**:
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'learning_rate': [0.01, 0.1, 0.5],
    'batch_size': [32, 64, 128],
    'hidden_units': [50, 100, 200]
}

grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy'
)
```

**随机搜索**:
```python
from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'learning_rate': [0.01, 0.1, 0.5],
    'batch_size': [32, 64, 128],
    'hidden_units': [50, 100, 200]
}

random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_dist,
    n_iter=10,
    cv=5,
    scoring='accuracy'
)
```

**贝叶斯优化**:
```python
from skopt import gp_minimize
from skopt.space import Real, Integer

space = [
    Real(0.01, 0.5, name='learning_rate'),
    Integer(32, 128, name='batch_size'),
    Integer(50, 200, name='hidden_units')
]

def objective(params):
    model = create_model(*params)
    score = cross_val_score(model, X, y, cv=5).mean()
    return -score

result = gp_minimize(objective, space, n_calls=50)
```

## 7. 模型集成

### 定义
模型集成是组合多个模型来提高预测性能的技术。

### 集成方法

**Bagging**:
- 并行训练多个模型
- 使用投票或平均
- 例子：随机森林
- 优点：减少方差

**Boosting**:
- 串行训练多个模型
- 后续模型关注前面模型的错误
- 例子：AdaBoost、Gradient Boosting
- 优点：减少偏差

**Stacking**:
- 使用元模型组合多个模型
- 训练元模型学习如何组合
- 优点：理论上最优
- 缺点：容易过拟合

**Blending**:
- 使用验证集训练元模型
- 避免过拟合
- 优点：简单有效
- 缺点：需要额外数据

### 集成策略
- **投票**：多数投票、加权投票
- **平均**：简单平均、加权平均
- **学习**：使用机器学习方法学习组合权重

## 8. 模型解释

### 定义
模型解释是理解模型如何做出预测的过程。

### 解释方法

**全局解释**:
- 特征重要性：哪些特征最重要
- 特征交互：特征之间的交互
- 模型结构：模型的结构和参数

**局部解释**:
- 单个预测的解释
- 特征贡献：每个特征的贡献
- 反事实解释：如果改变特征会怎样

### 解释技术

**传统方法**:
- 特征重要性：基于特征重要性排序
- 部分依赖图：显示特征对预测的影响
- 累积局部效应：显示特征对预测的累积影响

**现代方法**:
- SHAP：统一的可解释性框架
- LIME：局部可解释性
- 注意力机制：显示模型关注的部分

## 9. 模型监控

### 定义
模型监控是持续监控模型性能的过程。

### 监控内容
- **性能监控**：准确率、延迟、吞吐量
- **数据监控**：数据分布、数据质量
- **模型监控**：模型输出、置信度
- **业务监控**：业务指标、用户反馈

### 监控指标
- **准确率漂移**：模型准确率的变化
- **数据漂移**：输入数据分布的变化
- **概念漂移**：目标概念的变化
- **延迟漂移**：推理延迟的变化

### 监控工具
- **Prometheus**：指标收集
- **Grafana**：可视化
- **MLflow**：实验跟踪
- **Weights & Biases**：实验管理

## 10. 模型优化

### 优化目标
- **性能优化**：提高准确率、降低延迟
- **效率优化**：减少计算资源、降低功耗
- **鲁棒性优化**：提高对噪声的抵抗能力
- **可解释性优化**：提高模型的可解释性

### 优化方法

**算法优化**:
- 特征工程：构造更好的特征
- 模型选择：选择更合适的模型
- 超参数调优：优化超参数
- 集成学习：组合多个模型

**系统优化**:
- 模型压缩：量化、剪枝
- 硬件优化：使用专用硬件
- 并行计算：多线程、多进程
- 缓存策略：缓存计算结果

**数据优化**:
- 数据清洗：提高数据质量
- 数据增强：增加训练数据
- 数据平衡：处理类别不平衡
- 特征选择：选择重要特征
